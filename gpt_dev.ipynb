{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d61h6k4/EML/blob/main/gpt_dev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vL6PridenXjj",
        "outputId": "b42f428b-c625-490a-a293-90ae20b3b980"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.9.2)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-23.1.4-py2.py3-none-any.whl (26 kB)\n",
            "Collecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.29.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.2.0)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 KB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (15.0.6.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.25.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.16.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.0.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n",
            "Installing collected packages: flatbuffers, tensorflow-estimator, keras, tensorboard, tensorflow\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed flatbuffers-23.1.4 keras-2.11.0 tensorboard-2.11.2 tensorflow-2.11.0 tensorflow-estimator-2.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "D9N-UiUi4JMe"
      },
      "outputs": [],
      "source": [
        "import pathlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8ZDR-Qb34Wu",
        "outputId": "c87151f1-f647-42f8-92a4-1c1b873384bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-21 16:03:40--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-01-21 16:03:41 (57.5 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rYNVnW5S4FeB"
      },
      "outputs": [],
      "source": [
        "text = pathlib.Path(\"input.txt\").read_text()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUJMGrkb4O55",
        "outputId": "5b107549-675a-4652-d924-32932bcf9c42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of the text in characters: 1115394\n"
          ]
        }
      ],
      "source": [
        "print(f\"Length of the text in characters: {len(text)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYWf86PF4W4W",
        "outputId": "d9aaf757-03eb-42d2-92dc-3449a0b35d7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ]
        }
      ],
      "source": [
        "print(text[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnK6TqHF4bJv",
        "outputId": "86db26a9-1bdd-4167-d24b-68ee764cc5f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ],
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAipfOED4ozD",
        "outputId": "dabc8ee7-c1d3-4a14-bc4b-1ddf0a6854c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46, 47, 1, 58, 46, 43, 56, 43]\n",
            "hi there\n"
          ]
        }
      ],
      "source": [
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "itos = {i: ch for i, ch in enumerate(chars)}\n",
        "encode = lambda s: [stoi[ch] for ch in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "\n",
        "print(encode(\"hi there\"))\n",
        "print(decode(encode(\"hi there\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Yv4HA8yz5Yj6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LCBxoC076VXW"
      },
      "outputs": [],
      "source": [
        "data = tf.constant(encode(text), dtype=tf.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKhHg-DB6cLQ",
        "outputId": "cfae462c-1dff-46ca-c113-79285e29ad74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1115394,) <dtype: 'int64'>\n",
            "tf.Tensor(\n",
            "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
            "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
            " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
            "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
            "  0 37 53 59], shape=(100,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "print(data.shape, data.dtype)\n",
        "print(data[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6n6N6Lrt6zmF"
      },
      "outputs": [],
      "source": [
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FMZBFKH7Hde",
        "outputId": "fe5291ff-9b5f-4f6a-a932-1fad97268fa5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9,), dtype=int64, numpy=array([18, 47, 56, 57, 58,  1, 15, 47, 58])>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tEdR9er7lH3",
        "outputId": "962bee7d-8a1a-4dfb-d687-ecf6bbb39991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is [18] the target: 47\n",
            "when input is [18 47] the target: 56\n",
            "when input is [18 47 56] the target: 57\n",
            "when input is [18 47 56 57] the target: 58\n",
            "when input is [18 47 56 57 58] the target: 1\n",
            "when input is [18 47 56 57 58  1] the target: 15\n",
            "when input is [18 47 56 57 58  1 15] the target: 47\n",
            "when input is [18 47 56 57 58  1 15 47] the target: 58\n"
          ]
        }
      ],
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size + 1]\n",
        "\n",
        "for t in range(block_size):\n",
        "    context = x[:t + 1]\n",
        "    target = y[t]\n",
        "    print(f\"when input is {context} the target: {target}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq_oPYR48O8V",
        "outputId": "5398ffec-943f-45ad-fac8-8a26bcbff3e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "(4, 8)\n",
            "tf.Tensor(\n",
            "[[61 57  6  1 47 52  1 39]\n",
            " [56 57 11  0 35 46 47 41]\n",
            " [ 0 28 56 53 42 47 45 47]\n",
            " [46 43  1 52 53 40 50 43]], shape=(4, 8), dtype=int64)\n",
            "targets:\n",
            "(4, 8)\n",
            "tf.Tensor(\n",
            "[[57  6  1 47 52  1 39 52]\n",
            " [57 11  0 35 46 47 41 46]\n",
            " [28 56 53 42 47 45 47 53]\n",
            " [43  1 52 53 40 50 43 57]], shape=(4, 8), dtype=int64)\n",
            "----\n",
            "when input is [61] the target: 57\n",
            "when input is [61, 57] the target: 6\n",
            "when input is [61, 57, 6] the target: 1\n",
            "when input is [61, 57, 6, 1] the target: 47\n",
            "when input is [61, 57, 6, 1, 47] the target: 52\n",
            "when input is [61, 57, 6, 1, 47, 52] the target: 1\n",
            "when input is [61, 57, 6, 1, 47, 52, 1] the target: 39\n",
            "when input is [61, 57, 6, 1, 47, 52, 1, 39] the target: 52\n",
            "when input is [56] the target: 57\n",
            "when input is [56, 57] the target: 11\n",
            "when input is [56, 57, 11] the target: 0\n",
            "when input is [56, 57, 11, 0] the target: 35\n",
            "when input is [56, 57, 11, 0, 35] the target: 46\n",
            "when input is [56, 57, 11, 0, 35, 46] the target: 47\n",
            "when input is [56, 57, 11, 0, 35, 46, 47] the target: 41\n",
            "when input is [56, 57, 11, 0, 35, 46, 47, 41] the target: 46\n",
            "when input is [0] the target: 28\n",
            "when input is [0, 28] the target: 56\n",
            "when input is [0, 28, 56] the target: 53\n",
            "when input is [0, 28, 56, 53] the target: 42\n",
            "when input is [0, 28, 56, 53, 42] the target: 47\n",
            "when input is [0, 28, 56, 53, 42, 47] the target: 45\n",
            "when input is [0, 28, 56, 53, 42, 47, 45] the target: 47\n",
            "when input is [0, 28, 56, 53, 42, 47, 45, 47] the target: 53\n",
            "when input is [46] the target: 43\n",
            "when input is [46, 43] the target: 1\n",
            "when input is [46, 43, 1] the target: 52\n",
            "when input is [46, 43, 1, 52] the target: 53\n",
            "when input is [46, 43, 1, 52, 53] the target: 40\n",
            "when input is [46, 43, 1, 52, 53, 40] the target: 50\n",
            "when input is [46, 43, 1, 52, 53, 40, 50] the target: 43\n",
            "when input is [46, 43, 1, 52, 53, 40, 50, 43] the target: 57\n"
          ]
        }
      ],
      "source": [
        "def get_dataset(split, batch_size=4, block_size=8):\n",
        "    gen = tf.random.Generator.from_seed(1337)\n",
        "    data = train_data if split == \"train\" else val_data\n",
        "\n",
        "    maxval = len(data) - block_size\n",
        "\n",
        "    while True:\n",
        "        ix = gen.uniform((batch_size,), maxval=len(data) - block_size, dtype=tf.int32)\n",
        "        x = tf.stack([data[i:i+block_size] for i in ix])\n",
        "        y = tf.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "        yield x, y\n",
        "\n",
        "\n",
        "batch_size=4\n",
        "block_size=8\n",
        "\n",
        "xb, yb = next(get_dataset(\"train\", batch_size=batch_size, block_size=block_size))\n",
        "print(\"inputs:\")\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print(\"targets:\")\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "print(\"----\")\n",
        "\n",
        "for b in range(batch_size):\n",
        "    for t in range(block_size):\n",
        "        context = xb[b,:t+1]\n",
        "        target = yb[b, t]\n",
        "        print(f\"when input is {context.numpy().tolist()} the target: {target}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "MWrcY7si96TR"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "P6LysQIcn7TP"
      },
      "outputs": [],
      "source": [
        "class Head(keras.layers.Layer):\n",
        "    def __init__(self, block_size, head_size, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.key = keras.layers.Dense(head_size, use_bias=False)\n",
        "        self.query = keras.layers.Dense(head_size, use_bias=False)\n",
        "        self.value = keras.layers.Dense(head_size, use_bias=False)\n",
        "\n",
        "        self.dropout = keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, x):\n",
        "        T = tf.shape(x)[1]\n",
        "        C = tf.shape(x)[2]\n",
        "\n",
        "        k = self.key(x)\n",
        "        q = self.query(x)\n",
        "        wei = k @ tf.transpose(q, perm=[0, 2, 1]) * tf.math.rsqrt(tf.cast(C, tf.float32))\n",
        "        wei = tf.nn.softmax(tf.where(tf.linalg.band_part(tf.ones((T, T)), -1, 0) == 1, wei, float('-inf')), axis=-1)\n",
        "        wei = self.dropout(wei)\n",
        "\n",
        "        v = self.value(x)\n",
        "        out = wei @ v\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "IGMuMnt2rSkq"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(keras.layers.Layer):\n",
        "    def __init__(self, block_size, heads_num, head_size, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.heads = keras.Sequential([Head(block_size, head_size, dropout_rate=dropout_rate) for _ in range(heads_num)])\n",
        "        self.proj = keras.layers.Dense(heads_num * head_size)\n",
        "        self.dropout = keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, x):\n",
        "        out = tf.concat(self.heads(x), axis=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ndWXOzjXsv2b"
      },
      "outputs": [],
      "source": [
        "class FeedForward(keras.layers.Layer):\n",
        "    def __init__(self, n_embed, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.net = keras.Sequential([\n",
        "            keras.layers.Dense(4 * n_embed, activation=\"gelu\", use_bias=False),\n",
        "            keras.layers.Dense(n_embed, use_bias=False),\n",
        "            keras.layers.Dropout(dropout_rate)\n",
        "            ])\n",
        "\n",
        "    def call(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9My9X4UVui31"
      },
      "outputs": [],
      "source": [
        "class Block(keras.layers.Layer):\n",
        "    def __init__(self, block_size, n_embed, n_head, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        head_size = n_embed // n_head\n",
        "        self.sa_head = keras.layers.MultiHeadAttention(num_heads=n_head, key_dim=head_size, value_dim=None, dropout=dropout_rate, use_bias=False) # MultiHeadAttention(block_size, n_head, head_size, dropout_rate=dropout_rate)\n",
        "        self.ffwd = FeedForward(n_embed, dropout_rate=dropout_rate)\n",
        "        self.ln1 = keras.layers.LayerNormalization()\n",
        "        self.ln2 = keras.layers.LayerNormalization()\n",
        "\n",
        "    def call(self, x):\n",
        "        kv = self.ln1(x)\n",
        "        x = x + self.sa_head(kv, kv, use_causal_mask=True)\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NfIqq-BVAPGs"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class BigramLanguageModel(keras.Model):\n",
        "    def __init__(self, vocab_size, block_size, n_layer, n_head, n_embed=32, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "\n",
        "        self.token_embedding_table = keras.layers.Embedding(vocab_size, n_embed)\n",
        "        self.position_embedding_table = keras.layers.Embedding(block_size, n_embed)\n",
        "\n",
        "        self.blocks = keras.Sequential([\n",
        "            Block(block_size, n_embed, n_head, dropout_rate=dropout_rate) for _ in range(n_layer)\n",
        "            \n",
        "        ])\n",
        "        self.ls_ln = keras.layers.LayerNormalization()\n",
        "        self.lm_embed = keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def compile(self):\n",
        "        super().compile(optimizer=keras.optimizers.experimental.AdamW(learning_rate=3e-4),\n",
        "                        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                        jit_compile=True)\n",
        "\n",
        "    def call(self, idx):\n",
        "        T = tf.shape(idx)[1]\n",
        "\n",
        "        token_embed = self.token_embedding_table(idx)\n",
        "        pos_embed = self.position_embedding_table(tf.range(T))\n",
        "        x = token_embed + pos_embed\n",
        "        x = self.blocks(x)\n",
        "        x = self.ls_ln(x)\n",
        "        logits = self.lm_embed(x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -self.block_size:]\n",
        "            logits = self(idx_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            idx_next = tf.random.categorical(logits, num_samples=1, seed=1337)\n",
        "            idx = tf.concat([idx, idx_next], axis=1)\n",
        "\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCv0mbWzA8oR",
        "outputId": "414558f5-cf0b-42d4-98ca-24349ef97056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 8, 65)\n"
          ]
        }
      ],
      "source": [
        "block_size=256\n",
        "batch_size=64\n",
        "n_embed = 384\n",
        "n_head = 6\n",
        "n_layer = 6\n",
        "\n",
        "m = BigramLanguageModel(vocab_size, block_size=block_size, n_layer=n_layer, n_head=n_head, n_embed=n_embed, dropout_rate=0.2)\n",
        "logits = m(xb)\n",
        "print(logits.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "A7Q5QXBBHRjo"
      },
      "outputs": [],
      "source": [
        "m.compile()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwQCL84rRjsL",
        "outputId": "85122205-967b-4cc4-bdb9-fec1630583bb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"bigram_language_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  24960     \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     multiple                  98304     \n",
            "                                                                 \n",
            " sequential_6 (Sequential)   (4, 8, 384)               10626048  \n",
            "                                                                 \n",
            " layer_normalization_12 (Lay  multiple                 768       \n",
            " erNormalization)                                                \n",
            "                                                                 \n",
            " dense_12 (Dense)            multiple                  25025     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,775,105\n",
            "Trainable params: 10,775,105\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0OpONulEwhC",
        "outputId": "4fe0d53d-2369-4dd4-b48a-6c5ce7acda58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5000/5000 [==============================] - 3174s 629ms/step - loss: 1.4587 - val_loss: 1.6183\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f16b02221f0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# steps_per_epoch=5000,\n",
        "      \n",
        "\n",
        "m.fit(get_dataset(\"train\", block_size=block_size, batch_size=batch_size),\n",
        "     validation_data=get_dataset(\"val\", block_size=block_size, batch_size=batch_size),\n",
        "     steps_per_epoch=5000,\n",
        "      validation_steps=500,\n",
        "      shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "atOsXpUGFAy8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34d3870e-3d0f-43a0-8190-ce876330c40b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "That ever ever flow have ready were crown.\n",
            "\n",
            "Servant:\n",
            "Think you we that faults are salisk that this, by\n",
            "this fly head, and that am instrumented with\n",
            "honesty, or no? or who?\n",
            "\n",
            "PETRUCHIO:\n",
            "Vicested and the first served fish, which Barnardine\n",
            "sufficiences have scand make joy a joyful for\n",
            "you to death. Here's the way to pleasure out of it;\n",
            "whom we'll bear the feast, for the content,\n",
            "imputation of an end court. The other is required\n",
            "More frequal diving, three eyes to choose the custom, as\n",
            "please thou wh it was before thy bed, he's\n",
            "kind to me; what's no present to give him? I\n",
            "have done whom I must be made known that thee with for\n",
            "my heart; but thou dost consent to him wish this\n",
            "condition for Claudio.\n",
            "\n",
            "Clown:\n",
            "Indeed, sir.\n",
            "\n",
            "POMPEY:\n",
            "'Tis a son, a fond and elder, a virtuous worth.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "It is a Marcius in Claudio's this bed. Master\n",
            "allowed with our country renient may death. What is here\n",
            "matter did loss in Vienna? Plashy, madam, I were alDouble as steel;\n",
            "skell do the senators of their wood,\n",
            "the ancient of you blames both.\n",
            " HoRTENSIO:\n",
            "Men of Great sister, were not the people monads:\n",
            "With all gracious passage of mine\n",
            "The times of the world. But, as you beseech yourself\n",
            "\n",
            "MARCIUS:\n",
            "Good good night-his afternoon: ig 'em!\n",
            "The holy sickness whom i' the mantle,--\n",
            "I'll plead violent command, the trifle of death.\n",
            "Come, come, ten; let us be come.\n",
            "Whither 'scape o' the party, your master?\n",
            "\n",
            "All:\n",
            "What my will'?\n",
            "\n",
            "MENENIUS:\n",
            "Why, with my son?\n",
            "\n",
            "First Let's.\n",
            "\n",
            "COMINIUS:\n",
            "The Roman,\n",
            "Whom belly? sir, \n"
          ]
        }
      ],
      "source": [
        "print(decode(m.generate(tf.zeros((1,1), dtype=tf.int64), max_new_tokens=1500)[0].numpy().tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "YWQLZYKqcYBk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/IZGNsrVBtFB20L6UMdDF",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}